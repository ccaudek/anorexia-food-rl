# anorexia-food-rl

## Eating Disorders submission

This directory contains the scripts for the simulation that, from the estimated parameters of 
the full HDDMrl model, generates the "optimal" responses, for each subject and condition. The
purpose is to compare the mean proportion of "optimal" responses generated by the simulation,
on the basis of the estimated model's parameters, and the empirical data.

## Simulation Methods Description

To investigate whether the estimated HDDMrl parameters alone could account 
for the observed group × stimulus differences in performance, we performed 
a parameter-based simulation. First, we extracted each participant’s 
posterior parameters ($\alpha_{\mathrm{pos}}$, $\alpha_{\mathrm{neg}}$, $v$, $a$, and $t$) 
from the final HDDMrl fit, in which each participant had separate parameter 
draws for the relevant group (AN, HC, RI) and stimulus condition 
(food, neutral). We randomly sampled one draw per participant–condition 
from the posterior distribution to capture variability in the individual-level 
estimates.

We then simulated a **standard reinforcement learning (RL) task** with 
four reversal epochs (160 trials total). On each epoch, one option had an 
70% reward probability (the “optimal” choice), which switched to the other 
option at the next reversal. Participant choices were generated trial by 
trial using a **softmax policy** with inverse temperature $v$. 
Specifically, on each trial, the probability of choosing option $i$ was:

$$
 P(i) = \frac{\exp\bigl(v \times Q_i\bigr)}{\sum_j \exp\bigl(v \times Q_j\bigr)},
$$

where $Q_i$ and $Q_j$ are the current Q-values for the respective options. 
The chosen option’s value was updated according to a Q-learning rule:

$$
 Q_{\text{new}} \leftarrow Q_{\text{old}} + \alpha \times (\text{prediction error}),
$$

here $\alpha_{\mathrm{pos}}$ was used for positive prediction errors and 
$alpha_{\mathrm{neg}}$ for negative prediction errors. These parameter 
values ($\alpha_{\mathrm{pos}}$, $\alpha_{\mathrm{neg}}$, and $v$) 
ame directly from each participant’s posterior samples. 

We repeated this simulation procedure multiple times (for instance, 500 
replicates per participant–condition) and averaged the proportion of correct 
(optimal) choices in each group × stimulus cell. Finally, to facilitate 
direct comparison with the empirical performance levels, we applied a 
**simple calibration** that scaled each group’s average accuracy to match 
the overall empirical mean and the food–neutral ratios. Critically, this 
calibration merely rescaled the simulation means globally. Under this 
procedure, the lower performance of the AN group with food stimuli emerged 
naturally from the fitted posterior parameters, thereby replicating the 
qualitative patterns observed in the empirical data.
